{"metadata":{"kernelspec":{"display_name":"Spark 2.0.0 - Scala 2.11","language":"scala","name":"spark2-scala"},"language_info":{"codemirror_mode":"text/x-scala","file_extension":".scala","mimetype":"text/x-scala","name":"scala","pygments_lexer":"scala","version":"2.11.8"}},"nbformat":4,"nbformat_minor":2,"cells":[{"cell_type":"code","execution_count":0,"metadata":{"autoscroll":"auto"},"outputs":[],"source":"import scala.collection.JavaConversions._\n\n\n\nimport org.deeplearning4j.datasets.iterator._\nimport org.deeplearning4j.datasets.iterator.impl._\nimport org.deeplearning4j.nn.api._\nimport org.deeplearning4j.nn.multilayer._\nimport org.deeplearning4j.nn.graph._\nimport org.deeplearning4j.nn.conf._\nimport org.deeplearning4j.nn.conf.inputs._\nimport org.deeplearning4j.nn.conf.layers._\nimport org.deeplearning4j.nn.conf.graph.rnn.LastTimeStepVertex\nimport org.deeplearning4j.nn.weights._\nimport org.deeplearning4j.optimize.listeners._\nimport org.deeplearning4j.api.storage.impl.RemoteUIStatsStorageRouter\n//import org.deeplearning4j.ui.stats.StatsListener\nimport org.deeplearning4j.datasets.datavec.RecordReaderMultiDataSetIterator\nimport org.deeplearning4j.eval.Evaluation\n\nimport org.datavec.api.transform._\nimport org.datavec.api.records.reader.RecordReader\nimport org.datavec.api.records.reader.SequenceRecordReader\nimport org.datavec.api.records.reader.impl.csv.CSVRecordReader\nimport org.datavec.api.records.reader.impl.csv.CSVSequenceRecordReader\nimport org.datavec.api.split.NumberedFileInputSplit\n\nimport org.nd4j.linalg.activations.Activation\nimport org.nd4j.linalg.learning.config._\nimport org.nd4j.linalg.lossfunctions.LossFunctions._\nimport org.nd4j.linalg.factory.Nd4j\nimport org.nd4j.linalg.primitives.Pair\nimport org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator\nimport org.nd4j.linalg.dataset.api.preprocessor.MultiDataNormalization\nimport org.nd4j.linalg.dataset.api.preprocessor.MultiNormalizerStandardize\nimport org.nd4j.linalg.util.ArrayUtil\n\nimport java.io.File\nimport java.net.URL\nimport java.util.ArrayList\nimport java.util.Collections\nimport java.util.List\nimport java.util.Random\n\nimport org.apache.commons.io.IOUtils\nimport org.apache.commons.io.FileUtils\n\n"},{"cell_type":"code","execution_count":1,"metadata":{"autoscroll":"auto"},"outputs":[],"source":"\nval baseDir: File                         = new File(\"/tmp/uci-data\")\nval baseTrainDir: File                    = new File(baseDir, \"train\")\nval featuresDirTrain: File                = new File(baseTrainDir, \"features\")\nval labelsDirTrain: File                  = new File(baseTrainDir, \"labels\")\nval baseTestDir: File                     = new File(baseDir, \"test\")\nval featuresDirTest: File                 = new File(baseTestDir, \"features\")\nval labelsDirTest: File                   = new File(baseTestDir, \"labels\")\n\n\ndef downloadUCIData() {\n    //Data already exists\n    if (baseDir.exists()) {\n        print (s\"directory $baseDir already exists\")\n        return\n    }\n\n    val url: String =\n        \"https://archive.ics.uci.edu/ml/machine-learning-databases/synthetic_control-mld/synthetic_control.data\"\n    val data: String = IOUtils.toString(new URL(url))\n    val lines: Array[String] = data.split(\"\\n\")\n    print (s\"downloaded data from $url to $baseDir\")\n\n    // Perhaps redundant / unreachable code!\n    if (baseDir.exists()) {\n        baseDir.delete()\n    }\n\n    baseDir.mkdir()\n    baseTrainDir.mkdir()\n    featuresDirTrain.mkdir()\n    labelsDirTrain.mkdir()\n    baseTestDir.mkdir()\n    featuresDirTest.mkdir()\n    labelsDirTest.mkdir()\n\n    var lineCount: Int = 0\n    val contentAndLabels: List[Pair[String, Integer]] =\n        new ArrayList[Pair[String, Integer]]()\n        \n    for (line <- lines) {\n        val transposed: String = line.replaceAll(\" +\", \"\\n\")\n        //Labels: first 100 are label 0, second 100 are label 1, and so on\n\n        contentAndLabels.add(new Pair(transposed, (lineCount / 100)))\n        lineCount += 1\n    }\n\n    // Randomize and do a train/test split:\n    Collections.shuffle(contentAndLabels, new Random(12345))\n\n    \n}\n\n"}]}